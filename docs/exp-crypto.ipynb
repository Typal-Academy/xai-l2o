{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "zRmX2Fex4dGz"
      },
      "source": [
        "# Cryptoasset Trading\n",
        "\n",
        "The problem at hand is to train a model that reliably identifies arbitrage transactions for cryptoasssets within a network of constant function market makers (CFMMs). That is, given private valuation $p_i$ of the $i$-th cryptoasset, an analytic form of the task at hand is expressed via\n",
        "\n",
        "$$ \\min_{(x,y)} - U(x,y)\\ \\ \\text{s.t.} \\ \\ (x^j,y^j) \\ \\ \\text{forms a valid trade within the $j$-th CFMM with reserves $r^j$},$$\n",
        "\n",
        "where $r,p,x,y\\in\\mathbb{R}^n$ and the utility is\n",
        "\n",
        "$$ U(x,y) = \\sum_{j} \\left<  A^jp, A^j(y^j - x^j)\\right>,$$\n",
        "\n",
        "where $A^j$ maps $x^j$ and $y^j$ from global coordinates to local coordinates. (Note local coordinates may be in a smaller dimensional space since not all CFMMs utilize *all* cryptoassets.)\n",
        "\n",
        "As a simplified model of real-world phenomena, we introduce noise (*e.g.* due to front running) into the reserves $r$ to obtain noisy observable data $d$. This makes the problem inconsistent (we note below a simple mechanism for correcting this for this toy problem). To account for noise, a \"cost of risk\" is learned and incorporated in a data-driven utility $U_\\Theta$. This utility is optimized for a collection of training data to identify the optimal arbitrage trades. That is, we define an implicit model\n",
        "\n",
        "$$ \\mathcal{N}_\\Theta(d) \\triangleq (x_\\Theta, y_\\Theta) \\triangleq \\text{argmin}_{(x,y)} -U_\\Theta(x,y) \\ \\ \\text{s.t.} \\ \\ (x^j,y^j) \\ \\ \\text{forms a valid trade within the $j$-th CFMM with r}.$$\n",
        "\n",
        "The weights $\\Theta$ are tuned to solve the training problem\n",
        "\n",
        "$$ \\min_{\\Theta} \\mathbb{E}_{d\\sim\\mathcal{D}} \\left[  - U_\\Theta(x_\\Theta, \\tilde{y}_\\Theta)  \\right],$$\n",
        " \n",
        "where\n",
        "\n",
        "$$ \\tilde{y}_\\Theta^j = y_\\Theta^j - \\tau_j p$$\n",
        "\n",
        "and $\\tau_j$ is chosen so $(x^j_\\Theta, \\tilde{y}^j_\\Theta)$ forms a valid trade with the $j$-th CFMM that has reserves $r^j$. When $r^j = d^j$ and $U_\\theta = U$, we have $y_\\Theta^j = \\tilde{y}_\\Theta^j$. However, the presence of **noise** forces these to differ.\n",
        "\n",
        "<br>\n",
        "\n",
        "Below we overview the maths for the optimization algorithm. Then we define a PyTorch network that uses Davis-Yin Splitting (DYS) to compute inferences. Training is conducted by using [Jacobian-Free Backprop](https://arxiv.org/abs/2103.12803) (which maintains a low memory footprint by only backpropping through the final DYS iteration).\n",
        "\n",
        "<br>\n",
        "\n",
        "This notebook accompanies the preprint [Explainable AI via Learning to Optimize](https://research.typal.llc). In particular, see the appendices for more mathematical details about computations in this notebook.\n",
        "\n",
        "<br>\n",
        "\n",
        "**We emphasize the code herein is meant to be illustrative and, thus, has not be optimized for speed.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D9qbC92BlJUJ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "device= 'cuda:0'  "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "PwjgHzBUMkDp"
      },
      "source": [
        "# Levels of Abstraction in Math Formulation\n",
        "\n",
        "We begin at the highest level with the arbitrage problem\n",
        "\n",
        "$$ \\min_{(x,y)} \\sum_{j=1}^m \\left< A^jp, A^j(x^j - y^j)\\right>$$\n",
        "\n",
        "subject to the constraints\n",
        "\n",
        "$$ (x^j, y^j) = \\text{valid transaction with $j$-th CFMM with data $d^j$.}$$\n",
        "\n",
        "Here we assume CFMMs take use either a weighted arithmetic mean or weighted geometric mean for their constant function.  See our preprint for further detials on the constraints, their decoupling, and derivations of the proximal mappings for these. In our  setting, using the parameterization $\\xi=(v,x,y,z)$, we use the functions\n",
        "\n",
        "$$ f(\\xi;d) \\triangleq \\delta_{\\geq0}(x,y) + \\delta_{\\mathcal{M}}(v,z;d),$$\n",
        "\n",
        "$$ g(\\xi;d) \\triangleq \\delta_{\\mathcal{R}}(v,x,y) + \\delta_{\\mathcal{H}}(z;d),$$\n",
        "\n",
        "$$ h(\\xi;d) \\triangleq -U_\\Theta(x,y; d).$$\n",
        "\n",
        "The referenced indicator functions are given by\n",
        "\n",
        "$$ \\delta_{\\mathcal{M}}(v,z;d) \\triangleq \\sum_{i\\in\\mathcal{I}_1} \\delta_{\\mathcal{P}_j}(v^j, z^j;d) + \\sum_{j\\in\\mathcal{I}_2} \\delta_{\\mathcal{A}_j}(v^j;d),$$\n",
        "\n",
        "$$ \\delta_{\\mathcal{H}}(z) \\triangleq \\sum_{j\\in\\mathcal{I}_1} \\delta_{\\mathcal{H}_j} (z^j;d)$$\n",
        "\n",
        "$$ \\delta_{\\mathcal{R}}(v,x,y) \\triangleq \\sum_{j=1}^m \\delta_{\\mathcal{R}^j}(v^j,x^j,y^j),$$\n",
        "\n",
        "where $\\mathcal{I}_1$ is the set of all CFMM indices with weighted geometric means and $\\mathcal{I}_2 = [m] - \\mathcal{I}_1$ is the remaining indices for weighted arithmetic mean CFMMs, and\n",
        "\n",
        "$$ \\mathcal{P}_j \\triangleq \\{(v^j,z^j) : z^j \\leq \\ln(v^j + d) \\},$$\n",
        "\n",
        "$$ \\mathcal{A}_j \\triangleq \\{x^j : x+d^j \\geq 0,\\ \\left<w^j,x^j\\right> \\geq \\delta_j \\left<w,r^j\\right>,$$\n",
        "\n",
        "$$ \\mathcal{H}_j \\triangleq \\{z^j : \\left<w^j,z^j\\right> = \\ln(1-\\delta_j) + \\left<w^j, \n",
        "d^j\\right>\\},$$\n",
        "\n",
        "$$ \\mathcal{R}_j \\triangleq \\{(v^j,x^j,y^j) : v^j = \\Gamma^j A^j x^j - A^j y^j \\}.$$\n",
        "\n",
        "Above $\\Gamma^j = \\text{diag}(\\gamma_j,\\ldots,\\gamma_j) \\in \\mathbb{R}^{n_j\\times n_j}$ gives the trade fees within a CFMM and $A^j \\in \\mathbb{R}^{n_j\\times n}$ is a binary matrix that maps global cryptoasset indices into the local coordinates of each CFMM.\n",
        "\n",
        "<br>\n",
        "\n",
        "**Below we provide a function for applying DYS to lists of tensors**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "8_MjqeO-gGkg"
      },
      "source": [
        "# Davis-Yin Splitting\n",
        "\n",
        "From the above parameterizations, the arbitrage problem above is equivalent to the minimization problem\n",
        "\n",
        "$$ \\min_{\\xi} f(\\xi) + g(\\xi) + h(\\xi), $$\n",
        "\n",
        "where $f$ and $g$ are proximable and $h$ is $L$-Lipschitz differentiable. [Davis-Yin Splitting](https://arxiv.org/pdf/1504.01032.pdf) is applied, with $\\alpha \\in (0,2/L)$ via the iteration\n",
        "\n",
        "$$ \\xi^{k+1} = \\text{prox}_{\\alpha f}(\\zeta^k)$$\n",
        "$$ \\psi^{k+1} = \\text{prox}_{\\alpha g}(2\\xi^{k+1}-\\zeta^k - \\alpha \\nabla h(\\xi^{k+1}))$$\n",
        "$$ \\zeta^{k+1} = \\zeta^k + \\psi^{k+1}-\\xi^{k+1}$$\n",
        "\n",
        "Here\n",
        "\n",
        "$$ \\lim_{k\\rightarrow\\infty} \\xi^k = \\xi^\\star \\in \\text{argmin}_{\\xi} f(\\xi) + g(\\xi) + h(\\xi).$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tAmTeOBEMiCx"
      },
      "outputs": [],
      "source": [
        "def apply_DYS(prox_f, prox_g, grad_h, zeta_init, alpha, \n",
        "              fxd_pt_tol=1.0e-12, max_iters=1.0e3, verbose=False):\n",
        "    ''' Apply Davis-Yin Splitting to minimize f + g + h.\n",
        "\n",
        "        Convergence is measured by fixed point residual.\n",
        "\n",
        "        Preconditions: \n",
        "            - Step size is positive\n",
        "            - Stopping tolerance is positive\n",
        "            - Initialization is a tensor\n",
        "\n",
        "        Postconditions: \n",
        "            - xi and zeta shapes match\n",
        "\n",
        "        Note: We are unable to directly verify whether alpha < 2 / L, with L the\n",
        "              Lipschitz constant of h.\n",
        "    '''\n",
        "    assert alpha > 0\n",
        "    assert fxd_pt_tol > 0\n",
        "    assert torch.is_tensor(zeta_init)\n",
        "\n",
        "    zeta = zeta_init.clone()\n",
        "    converge = False\n",
        "    iter = 0 \n",
        "    while not converge and iter < max_iters:\n",
        "        xi = prox_f(zeta, alpha)    \n",
        "        psi = prox_g(2.0 * xi - zeta - alpha * grad_h(xi), alpha)\n",
        "        zeta = zeta + psi - xi\n",
        "\n",
        "        fix_pt_res = torch.max(torch.norm(psi - xi, dim=1))        \n",
        "        ref_norm = torch.mean(torch.norm(zeta, dim=1))\n",
        "        # converge = fix_pt_res <= fxd_pt_tol * ref_norm \n",
        "        converge = False\n",
        "        iter += 1   \n",
        "\n",
        "    if verbose and iter == max_iters:\n",
        "        print('DYS reached max iteration count.')  \n",
        "\n",
        "    valid_shape = xi.shape[0] == zeta_init.shape[0]\n",
        "    valid_shape = xi.shape[1] == zeta_init.shape[1] and valid_shape\n",
        "    assert valid_shape\n",
        "\n",
        "    return prox_f(zeta, alpha), zeta"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "CHIT2VB5S5Fu"
      },
      "source": [
        "# Cryptoasset Trade Utility\n",
        "\n",
        "The differentiable function $h$ gives the trade utility, *i.e.* \n",
        "\n",
        "$$h(\\xi;d) \\triangleq  -U_\\Theta(x,y;d) = \\underbrace{\\sum_{j=1}^m \\left<   A^j p,   A^j(x^j-y^j) \\right>}_{\\text{net value lossed}} + \\underbrace{\\dfrac{\\psi_\\Theta(d)}{2}\\sum_{j=1}^m   \\left\\|W^j A^j (x^j - y^j)) \\right\\|^2 .}_{\\text{Risk term}}, $$\n",
        "\n",
        "Sigmoid... (CHECK LIPSCHITZ STUFF)\n",
        "\n",
        "$$ \\sigma(z) = \\dfrac{1}{1+\\exp(-z)}\\ \\ \\implies \\ \\ \\nabla \\sigma(z) = \\sigma(z)\\cdot(1-\\sigma(z)).$$\n",
        "\n",
        "$$  \\psi_\\Theta(d) \\cdot   A^\\top W^\\top WA(x-y) \\cdot \\text{diag}(\\sigma' (WA(x-y)+b)) $$\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "where $\\Theta$ are weights consisting of $W$ and parameters for $\\psi_\\Theta:\\mathbb{R}^n\\rightarrow \\mathbb{R}$. The function $\\psi_\\Theta$ is   continuous, but is *not* (necessarily) convex in $d$. The oracle for utility takes the form of a gradient. To this end, set\n",
        "\n",
        "$$ W \\triangleq \\text{diag}(W^1,\\ldots, W^m),  \\ \\ \\ A \\triangleq \\text{diag}(A^1,\\ldots,A^m),$$\n",
        "\n",
        "and\n",
        "\n",
        "$$ S \\triangleq \\left[\\begin{array}{c} \\mathrm{I} \\\\ \\vdots \\\\ \\mathrm{I} \\end{array}\\right] \\in \\mathbb{R}^{mn\\times n}.$$\n",
        "\n",
        "Then, in full scale,\n",
        "\n",
        "$$ -U(x,y) = p^\\top S^\\top A^\\top A (x-y)   + \\dfrac{\\psi_\\Theta(d)}{2} \\| W A(x-y)\\|^2,$$\n",
        "\n",
        "which implies\n",
        " \n",
        "\n",
        "$$ -\\nabla_{x} U(x,y) = A^\\top ASp +  \\psi_\\Theta(d) A^\\top W^\\top  W A(x-y).$$\n",
        "\n",
        "Noting the flipped signs between $x$ and $y$, we see\n",
        "\n",
        "$$ \\nabla_{y} U(x,y) = -  \\nabla_{x} U(x,y).$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xKuh56XtP0iQ"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn \n",
        "\n",
        "activation = nn.Sigmoid()\n",
        "leaky_relu = nn.LeakyReLU(0.01)\n",
        "\n",
        "def grad_neg_U(x, y, p, W, A, psi, num_cfmms):\n",
        "    ''' Compute gradient of -U(x,y) with respect to x.\n",
        "\n",
        "        Preconditions: \n",
        "            - Each input is a tensor (other than 'num_cfmms')\n",
        "            - Tensor shapes match\n",
        "\n",
        "        Postconditions:\n",
        "            - Output grad shape matches x shape\n",
        "\n",
        "        Note: The gradient with respect to y is obtained by flipping signs\n",
        "    '''\n",
        "    for val in [x, y, p, W, A]:\n",
        "        assert torch.is_tensor(val)          \n",
        "\n",
        "    assert x.shape[0] == num_cfmms * p.shape[0]\n",
        "    assert x.shape[0] == y.shape[0]\n",
        "    assert x.shape[0] == A.shape[1]\n",
        "    assert W.shape[0] == A.shape[0]\n",
        "    assert W.shape[0] == W.shape[1]\n",
        "    \n",
        "    AA = torch.mm(A.permute(1,0), A).to(device) \n",
        "    WA = torch.mm(W, A).to(device) \n",
        "    AWWA = torch.mm(WA.permute(1,0), WA).to(device)\n",
        " \n",
        "    Sp = torch.cat([p for _ in range(num_cfmms)], dim=0).to(device)\n",
        "    cost_term = torch.mm(AA, Sp)\n",
        "    \n",
        "    \n",
        "    risk_term = torch.mm(AWWA, x - y) * psi \n",
        "    # risk_term = torch.mm(AWWA, x - y) * torch.mm(A.permute(1,0), psi)\n",
        "\n",
        "    grad = cost_term + risk_term   \n",
        "    return grad.to(device)\n",
        "\n",
        "def grad_h(xi, p, W, A, psi, num_cfmms):\n",
        "    ''' Compute gradient of h(xi) = - U(x,y) where xi = (v, x, y, z).\n",
        "\n",
        "        Precondition:\n",
        "            - Inputs are tensors and a scalar\n",
        "        \n",
        "        Postcondition:\n",
        "            - Output grad shape matches input xi shape\n",
        "\n",
        "        Note: The x and y components of gradient are negatives of each other.\n",
        "              The indexing of x and y blocks in the tuple xi is done using\n",
        "              dummy variables 'q' and 'm'. Also, the v and z blocks of the\n",
        "              gradient are automatically zero since there is no dependence in h\n",
        "              on these blocks.\n",
        "    '''\n",
        "    for val in [xi, p, W, A]:\n",
        "        assert torch.is_tensor(val) \n",
        "\n",
        "    q = A.shape[0]\n",
        "    m = A.shape[1]\n",
        "    grad = xi.clone() \n",
        "\n",
        "    grad[0:q, :] = torch.zeros(grad[0:q, :].shape)\n",
        "    grad[-q:, :] = torch.zeros(grad[0:q, :].shape)\n",
        "\n",
        "    grad[q:q+m, :] = grad_neg_U(xi[q:q+m, :], xi[q+m:q+2*m, :],p, W, A,\n",
        "                                psi, num_cfmms)     \n",
        "    grad[q+m:q+2*m, :] = - grad[q:q+m, :]\n",
        "\n",
        "    valid_shape = grad.shape[0] == xi.shape[0] and grad.shape[1] == xi.shape[1]\n",
        "    assert valid_shape\n",
        "\n",
        "    return grad   "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "qLD8aJL6_sow"
      },
      "source": [
        "# Geometric Mean Constraints\n",
        "\n",
        "Next we look at blockwise-projections onto the hyperplanes\n",
        "\n",
        "$$ \\mathcal{H}_j = \\left\\lbrace z^j : \\left<w^j,z^j\\right> = \\ln(1+\\delta_j) + \\ln\\left( \\left<w^j, d^j\\right>\\right)\\right\\rbrace, \\ \\ \\ \\text{for all $j\\in[m]$.}$$\n",
        "\n",
        "The formula for the $j$-th hyperplane projection is\n",
        "\n",
        "$$ P_{\\mathcal{H}_j}(z^j) = z^j - \\dfrac{\\left<w^j,z^j\\right>-b(d^j)}{\\|w^j\\|^2} w^j.$$\n",
        "\n",
        "where\n",
        "\n",
        "$$ b(d^j) = \\ln(1+\\delta_j) + \\left<w, \\ln(d^j)\\right>.$$\n",
        "\n",
        "Generalizing to all blocks gives the constraint\n",
        "\n",
        "$$ \\mathcal{H} = \\mathcal{H}_1 \\times \\mathcal{H}_2 \\times \\cdots \\times \\mathcal{H}_m .$$\n",
        "\n",
        "The projection on $\\mathcal{H}$ is given by\n",
        "\n",
        "$$ P_\\mathcal{H}(z) = z - N(z) w, $$\n",
        "\n",
        "where\n",
        "\n",
        "$$ N(z) \\triangleq \\text{diag}\\left( \\mu_1(z) \\mathrm{I}, \\ldots, \\mu_m(z) \\mathrm{I} \\right),$$\n",
        "\n",
        "<br>\n",
        "\n",
        "$$\\delta_{jg} \\triangleq \\begin{cases}\\begin{array}{cl} 1 & \\text{if $j$-th constraint is geometric}, \\\\ 0 & \\text{otherwise,}\\end{array}\n",
        "\\end{cases}$$\n",
        "\n",
        "and\n",
        "\n",
        "$$ \\mu(z) \\triangleq \\text{diag}\\left(\\delta_{1g}\\|w^1\\|^{-2},\\ldots,\\delta_{mg}\\|w^m\\|^{-2}\\right)\\left[\\text{diag}\\left( (w^1)^\\top,\\ldots, (w^m)^\\top  \\right) \\cdot (z-\\ln(d)) - \\ln(1-\\delta)\\right].  $$\n",
        "\n",
        "\n",
        "<br>\n",
        "\n",
        "*Note* the inclusion of $\\delta_{jg}$ means $\\mathcal{H}$ is not actually a tuple of just $\\mathcal{H}_j$ sets since some of these sets are simply all of $\\mathbb{R}^{n_j}$.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o_2tW4dGfM6t"
      },
      "outputs": [],
      "source": [
        "def prox_H(z, w, d, delta, geo_indices, cfmm_type):\n",
        "    ''' Project z onto Cartesian product of hyperplanes.\n",
        "\n",
        "        Inputs:\n",
        "                      z - vector to project, z = (z1 z2 ... zj ... zm)\n",
        "                      w - vector for scalar product, w = (w1 w2 ... wj ... wm)\n",
        "                      d - data vector, d = (d1 d2 ... dj ... dm)\n",
        "                  delta - tolerances for projection\n",
        "            geo_indices - list of indices for each CFMM\n",
        "              cfmm_type - list of booleans identifying which CFMMs are geometric\n",
        "        \n",
        "        Output:\n",
        "            prox - projection of z onto H, the product of hyperplanes\n",
        "\n",
        "        Preconditions:\n",
        "            - All inputs are tensors or lists of tensors\n",
        "            - Tensors w, z, and d are same shape\n",
        "        Postconditions:\n",
        "            - Output prox has same shape as input z\n",
        "    '''\n",
        "    assert torch.is_tensor(z)     \n",
        "    assert torch.is_tensor(w)   \n",
        "    assert torch.is_tensor(d)   \n",
        "    assert torch.is_tensor(delta)     \n",
        "    assert isinstance(geo_indices, list)\n",
        "    assert isinstance(cfmm_type, list)\n",
        "    assert all([torch.is_tensor(entry) for _, entry in enumerate(cfmm_type)])\n",
        "    #assert torch.equal(z.shape, w.shape)\n",
        "    #assert torch.equal(z.shape, d.shape)\n",
        "\n",
        "    zd = z - torch.log(d) \n",
        "    wzd = torch.cat([torch.mm(w[idx, :].permute(1,0), zd[idx, :])\n",
        "                     for idx in geo_indices], dim=0) \n",
        "    wzd_d = wzd - torch.log(1.0 + delta) \n",
        "    w_inv = torch.cat([cfmm_type[j] * (torch.norm(w[idx, :]) ** - 2.0)\n",
        "                       for j, idx in enumerate(geo_indices)], dim=0) \n",
        "    mu = torch.mm(torch.diag(w_inv), wzd_d) \n",
        "    Nw = torch.cat([mu[j] * w[idx, :] for j, idx in enumerate(geo_indices)],\n",
        "                   dim=0) \n",
        "    prox = z - Nw\n",
        "\n",
        "    # assert torch.equal(z.shape, prox.shape)\n",
        "    \n",
        "    return prox"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "JEM1rz41Axh7"
      },
      "source": [
        "## Halfspace Constraints\n",
        "\n",
        "Next we look at projections on the set\n",
        "\n",
        "$$ \\mathcal{A}_j = \\left\\lbrace v : \\left<w^j, v\\right>  \\geq  \\delta_j \\left<w^j, d^j\\right> \\right\\rbrace.$$\n",
        "\n",
        "The formula is\n",
        "\n",
        "$$ P_{\\mathcal{A}_j}(v) = v - \\dfrac{\\left[\\left<w^j,v\\right> -  \\delta_j\\left<w^j, d^j\\right>\\right]_-}{\\|w^j\\|^2} w^j.$$\n",
        "\n",
        "Generalizing to all blocks gives the constraint\n",
        "\n",
        "$$ \\mathcal{A} = \\mathcal{A}_1 \\times \\mathcal{A}_2 \\times \\cdots \\times \\mathcal{A}_m .$$\n",
        "\n",
        "The projection on $\\mathcal{A}$ is given by\n",
        "\n",
        "$$ P_{\\mathcal{A}}(z) = z - N(z) w, $$\n",
        "\n",
        "where\n",
        "\n",
        "$$ N(z) \\triangleq \\text{diag}\\left( \\mu_1(z) \\mathrm{I}, \\ldots, \\mu_m(z) \\mathrm{I} \\right),$$\n",
        "\n",
        "<br>\n",
        "\n",
        "$$\\delta_{ja} \\triangleq \\begin{cases}\\begin{array}{cl} 1 & \\text{if $j$-th constraint is arithmetic}, \\\\ 0 & \\text{otherwise,}\\end{array}\n",
        "\\end{cases}$$\n",
        "\n",
        "and\n",
        "\n",
        "$$ \\mu(z) \\triangleq \\left[ \\text{diag}\\left(\\delta_{1a}\\|w^1\\|^{-2},\\ldots,\\delta_{ma}\\|w^m\\|^{-2}\\right) \\cdot\\text{diag}\\left( (w^1)^\\top,\\ldots, (w^m)^\\top  \\right) \\cdot  (v+\\delta d)\\right]_-.  $$\n",
        "\n",
        "\n",
        "<br>\n",
        "\n",
        "*Note* the inclusion of $\\delta_{jg}$ means $\\mathcal{A}$ is not actually a product of just $\\mathcal{A}_j$ sets since some of these sets are simply all of $\\mathbb{R}^{n_j}$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EwQCICv17Ti9"
      },
      "outputs": [],
      "source": [
        "def prox_A(v, w, d, delta, geo_indices, cfmm_type):\n",
        "    ''' Project v onto Cartesian product of halfspaces.\n",
        "\n",
        "        Inputs:\n",
        "                      v - vector to project, v = (v1 v2 ... vj ... vm)\n",
        "                      w - vector for scalar product, w = (w1 w2 ... wj ... wm)\n",
        "                      d - data vector, d = (d1 d2 ... dj ... dm)\n",
        "                  delta - tolerances for projection\n",
        "            geo_indices - list of indices for each CFMM\n",
        "              cfmm_type - list of booleans identifying which CFMMs are geometric\n",
        "        \n",
        "        Output:\n",
        "            prox - projection of v onto A, the product of halfspaces\n",
        "\n",
        "        Note:\n",
        "            Here cfmm_type must be negated (i.e. use 1 - type) to get delta_{ja}\n",
        "            since we are interested in arithemtic CFMM constraints, *not* \n",
        "            geometric CFMM constraints.\n",
        "    '''\n",
        "    assert torch.is_tensor(v)   \n",
        "    assert torch.is_tensor(w)   \n",
        "    assert torch.is_tensor(d)   \n",
        "    assert torch.is_tensor(delta)        \n",
        "    assert isinstance(geo_indices, list)\n",
        "    assert isinstance(cfmm_type, list)\n",
        "    assert all([torch.is_tensor(entry) for _, entry in enumerate(cfmm_type)])\n",
        "\n",
        "    # delta = [11, 1]\n",
        "    # d = [11, batch size]\n",
        "    \n",
        "    dd = (delta * d).to(device)\n",
        "    #dd = torch.cat([delta[j] * d[idx, :] for j, idx in enumerate(geo_indices)],\n",
        "    #               dim=0).to(device)\n",
        "    vd = v - dd\n",
        "    wvd = torch.cat([torch.mm(w[idx, :].permute(1,0), vd[idx, :])\n",
        "                     for idx in geo_indices], dim=0).to(device)\n",
        "    w_inv = torch.cat([(1.0 - cfmm_type[j]) * (torch.norm(w[idx, :]) ** - 2.0)\n",
        "                       for j, idx in enumerate(geo_indices)],\n",
        "                      dim=0).to(device)\n",
        "    mu = torch.clamp(torch.mm(torch.diag(w_inv), wvd), max=0.0).to(device)\n",
        "    Nw = torch.cat([mu[j] * w[idx, :] for j, idx in enumerate(geo_indices)],\n",
        "                   dim=0).to(device)\n",
        "    prox = v - Nw\n",
        "    return prox"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "jmyvVM0-B-8_"
      },
      "source": [
        "## Linear System Constraints\n",
        "\n",
        "Next we consider the linear system\n",
        "$$ \\mathcal{R}_j \\triangleq \\{(v^j,x^j,y^j) : v^j = \\gamma_j A^j x^j - A^jy^j\\}, \\ \\ \\text{for all $j\\in[m]$.}$$\n",
        "\n",
        "Generalizing to all blocks gives the constraint\n",
        "\n",
        "$$ \\mathcal{R} \\triangleq \\mathcal{R_1}\\times\\mathcal{R_2}\\times\\cdots\\times \\mathcal{R_m} = \\{ (v,x,y) : v = \\Gamma Ax - Ay \\},$$\n",
        "\n",
        "where\n",
        "\n",
        "$$ A \\triangleq \\text{diag}(A^1,\\ldots, A^m) \\ \\ \\text{and} \\ \\ \\Gamma \\triangleq \\text{diag}(\\gamma_1 \\mathrm{I}, \\ldots, \\gamma_m \\mathrm{I}). $$\n",
        "\n",
        "Setting\n",
        "\n",
        "$$ N \\triangleq [\\Gamma A \\ \\ -A] \\ \\ \\text{and} \\ \\ M \\triangleq (\\mathrm{I}+N^\\top N)^{-1}$$\n",
        "\n",
        "yields \n",
        "\n",
        "$$ \\left[P_{R}(v,x,y)\\right]_{(x,y)} = M\\left[\\begin{array}{c} x+A^\\top \\Gamma v \\\\ y - A^\\top v\\end{array}\\right], $$\n",
        "\n",
        "from which the $v$ component is of the projection is directly obtained by matrix multiplication."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YpzXcudICBSl"
      },
      "outputs": [],
      "source": [
        "def prox_R(v, x, y, A, Gamma):\n",
        "    ''' Project (v,x,y) onto constraint set v = A * (Gamma * x - y)\n",
        "    '''\n",
        "    for val in [v, x, y, A, Gamma]:\n",
        "        assert torch.is_tensor(val)\n",
        "    # XXX - Check that shapes match up!\n",
        "\n",
        "    prox_v = v.clone()\n",
        "    prox_x = x.clone()\n",
        "    prox_y = y.clone()\n",
        "    \n",
        "    N = torch.cat((torch.mm(Gamma, A), -A), dim=1).to(device)\n",
        "    NN = torch.mm(N.permute(1,0), N).to(device)\n",
        "    I = torch.diag(torch.ones(NN.shape[0])).to(device)\n",
        "    M = torch.linalg.inv(I + NN).to(device)\n",
        "    \n",
        "    AGv = torch.mm(A.permute(1,0), torch.mm(Gamma, v)).to(device)\n",
        "    Av = torch.mm(A.permute(1,0), v).to(device)\n",
        "    xy = torch.cat((x + AGv, y - Av), dim=0).to(device)\n",
        "    prox_xy = torch.mm(M, xy).to(device)\n",
        "    prox_x = prox_xy[:x.shape[0], :]\n",
        "    prox_y = prox_xy[x.shape[0]:, :]\n",
        "\n",
        "    GAx = torch.mm(Gamma, torch.mm(A, prox_x)).to(device)\n",
        "    Ay = torch.mm(A, prox_y).to(device)\n",
        "    prox_v = GAx - Ay\n",
        "\n",
        "    return prox_v, prox_x, prox_y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jo6oUF-2P7n8"
      },
      "source": [
        "## Logarithmic Constraints\n",
        "\n",
        "Lastly, we consider the set\n",
        "\n",
        "$$ \\mathcal{P} = \\{(v,z) : \\ln(v+d) \\geq z \\}.$$\n",
        "\n",
        "\n",
        "The projection $(\\overline{v},\\overline{z})$ of $(v,z)$ onto $\\mathcal{P}$ satisfies\n",
        "\n",
        "$$ 0 = (\\overline{v} + d) \\odot (\\overline{v} - {v})  + \\ln(\\overline{v}+d) - z.$$\n",
        "\n",
        "Since the relations are element-wise and separable, we compute the projection $(\\overline{x}, \\overline{z})$ using Newton iteration. Treating the right hand side like $f(\\hat{v})$ and differentiating $f:\\mathbb{R}\\rightarrow\\mathbb{R}$ gives\n",
        "\n",
        "$$ f'(\\hat{v}) =  2\\hat{v} + (d-v) + \\dfrac{1}{\\hat{v}+d}.$$\n",
        "\n",
        "Then Newton iteration takes the form\n",
        "\n",
        "$$ \\hat{v}^{k+1} = \\hat{v}^k - \\dfrac{f(\\hat{v}^k)}{ f'(\\hat{v}^k)}.$$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T-okPpPIQD-l"
      },
      "outputs": [],
      "source": [
        "def prox_P(v, z, d, newton_steps=10):\n",
        "    ''' Project (v, z) onto constraint set { (v,z) : ln(v + d) <= z }.\n",
        "    ''' \n",
        "    assert torch.is_tensor(v)\n",
        "    assert torch.is_tensor(z)\n",
        "    assert torch.is_tensor(d)\n",
        "\n",
        "    #print(\"v.shape = \", v.shape)\n",
        "    #print(\"z.shape = \", z.shape)\n",
        "    #print(\"d.shape = \", d.shape)\n",
        "\n",
        "\n",
        "    with torch.no_grad(): \n",
        "        #print(\"v.shape = \", v.shape)\n",
        "        #print(\"d.shape = \", d.shape)\n",
        "        #print(\"z.shape = \", z.shape)\n",
        "        indices = v + d < torch.exp(z)\n",
        "                    \n",
        "        vv = v[indices]\n",
        "        dd = d[indices]\n",
        "        pv = torch.max(vv, -dd + 0.5 * torch.abs(dd))\n",
        "        zz = z[indices]\n",
        "        \n",
        "        for _ in range(newton_steps): \n",
        "            fv = (pv + dd) * (pv - vv) + torch.log(pv + dd) - zz \n",
        "            fpv = 2 * pv + (dd - vv) + ((pv + dd) ** -1.0) \n",
        "            pv = torch.max(pv - fv / fpv, -dd + 1.0e-6 * torch.abs(dd)) \n",
        "                    \n",
        "        prox_v = v.clone()\n",
        "        prox_z = z.clone()\n",
        "\n",
        "        prox_v[indices] = pv.clone()\n",
        "        prox_z[indices] = torch.log(pv + dd)\n",
        "\n",
        "    return prox_v, prox_z"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iT7sYwCJA9Zx"
      },
      "source": [
        " ## Projection onto sum of constraints\n",
        "\n",
        " Next we consider the set $\\mathcal{M}$, which is most easily expressed by using the sum of indicator functions, i.e.\n",
        " \n",
        " $$\\delta_{\\mathcal{M}}(\\xi) \\triangleq \\sum_{i\\in\\mathcal{I}_1} \\delta_{\\mathcal{P}_j}(v^j, z^j) + \\sum_{j\\in\\mathcal{I}_2} \\delta_{\\mathcal{A}_j}(v^j).$$\n",
        "\n",
        " This function marks a transition of input types. Now we use $\\xi = (v,x,y,z)$. For implementation, $\\xi$ is a list, i.e. $\\xi = [v, x, y, z]$ where each component is itself a list of tensors, one tensor for each CFMM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l94W3_QbA8MR"
      },
      "outputs": [],
      "source": [
        "def prox_M(xi, d, w, delta, geo_indices, cfmm_types):\n",
        "    ''' Test...\n",
        "\n",
        "        lsdjf\n",
        "    '''\n",
        "    assert torch.is_tensor(xi)\n",
        "    assert torch.is_tensor(d)\n",
        "    assert torch.is_tensor(w)\n",
        "    # XXX - preconditions\n",
        "\n",
        "    q = A.shape[0]\n",
        "    m = A.shape[1]\n",
        " \n",
        "    v_idx = range(q)\n",
        "    x_idx = range(q, q+m)\n",
        "    y_idx = range(q+m,q+2*m)\n",
        "    z_idx = range(q+2*m, xi.shape[0])\n",
        "    \n",
        "    prox = xi.clone()\n",
        "\n",
        "    prox_v, prox_z = prox_P(xi[v_idx, :], xi[z_idx, :], d)\n",
        "    prox_v = prox_A(prox_v, w, d, delta, geo_indices, cfmm_types)\n",
        "\n",
        "    prox[v_idx, :] = prox_v\n",
        "    prox[z_idx, :] = prox_z\n",
        "\n",
        "    return prox"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AYZkbVmHG28j"
      },
      "source": [
        "## Proximal of $f$\n",
        "\n",
        "Moving to the highest level of abstraction, we obtain\n",
        "\n",
        "$$f(\\xi) \\triangleq \\delta_{\\geq0}(x,y) + \\delta_{\\mathcal{M}}(v,z).$$\n",
        "\n",
        "Because the two terms of $f$ depend on different components of $\\xi$, we may apply the proximals sequentially."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AYYOBnVN11tI"
      },
      "outputs": [],
      "source": [
        "def prox_f_model(xi, d, w, delta, geo_indices, cfmm_types):\n",
        "    '''\n",
        "        xi = (v, x, y, z)\n",
        "\n",
        "        Note: We first project on M. Then we threshold the x and y values.\n",
        "        \n",
        "        XXX - NEED TO MAKE TESTS FOR THIS\n",
        "    '''\n",
        "    q = A.shape[0]\n",
        "    m = A.shape[1] \n",
        "\n",
        "    v_idx = range(q)\n",
        "    x_idx = range(q, q+m)\n",
        "    y_idx = range(q+m,q+2*m)\n",
        "    z_idx = range(q+2*m, xi.shape[0])\n",
        "\n",
        "    prox = prox_M(xi, d, w, delta, geo_indices, cfmm_types)\n",
        "    prox[x_idx, :] = torch.clamp(prox[x_idx, :], min=0.0).to(device)\n",
        "    prox[y_idx, :] = torch.clamp(prox[y_idx, :], min=0.0).to(device)\n",
        "\n",
        "    return prox"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4z2CWyZcHqH2"
      },
      "source": [
        "## Proximal of $g$\n",
        "\n",
        "The final function to compute proximals for is\n",
        "\n",
        "$$g(\\xi) \\triangleq \\delta_{\\mathcal{R}}(v,x,y) + \\delta_{\\mathcal{H}}(z).$$\n",
        "\n",
        "Since the components used by each of the two terms do not overlap, we can apply the proximal for each successively."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "On536galH2KS"
      },
      "outputs": [],
      "source": [
        "def prox_g_model(xi, d, w, delta, geo_indices, cfmm_types, A, Gamma):\n",
        "    ''' fff\n",
        "    '''\n",
        "    q = A.shape[0]\n",
        "    m = A.shape[1]\n",
        "\n",
        "    v_idx = range(q)\n",
        "    x_idx = range(q, q+m)\n",
        "    y_idx = range(q+m,q+2*m)\n",
        "    z_idx = range(q+2*m, xi.shape[0])\n",
        "    \n",
        "    prox = torch.zeros(xi.shape).to(device)\n",
        "    v, x, y = prox_R(xi[v_idx, :], xi[x_idx, :], xi[y_idx, :], A, Gamma)\n",
        "\n",
        "    prox[v_idx, :] = v\n",
        "    prox[x_idx, :] = x\n",
        "    prox[y_idx, :] = y\n",
        "    prox[z_idx, :] = prox_H(xi[z_idx, :], w, d, delta, geo_indices, cfmm_types)\n",
        "    return prox"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M21b_PAywDLg"
      },
      "source": [
        "## PyTests\n",
        "\n",
        "Various tests are used to check aspects of the above functions (mimicking what one usually encodes as pytests in a .py file)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c1GZQyPl-_wQ"
      },
      "outputs": [],
      "source": [
        "def get_block_diag(mats):\n",
        "    ''' Create block diagonal matrix from list of tensors.\n",
        "    '''\n",
        "    assert isinstance(mats, list)\n",
        "    assert all([torch.is_tensor(entry) for _, entry in enumerate(mats)])    \n",
        "    \n",
        "    mat = mats[0].to(device)\n",
        "    for j, val in enumerate(mats):\n",
        "        if j > 0:\n",
        "            zeros_top = torch.zeros(mat.shape[0], val.shape[1]).to(device)\n",
        "            zeros_bot = torch.zeros(val.shape[0], mat.shape[1]).to(device)\n",
        "            mat_top = torch.cat((mat, zeros_top), dim=1).to(device)\n",
        "            mat_bot = torch.cat((zeros_bot, val.to(device)), dim=1).to(device)\n",
        "            mat = torch.cat((mat_top, mat_bot), dim=0).to(device)\n",
        "    return mat\n",
        "\n",
        "def get_cfmm_indices(cfmm_sizes):\n",
        "    n_cfmms = len(cfmm_sizes)\n",
        "    idx_lo = 0\n",
        "    cfmm_indices = []\n",
        "\n",
        "    for j in range(n_cfmms):\n",
        "        idx_hi = idx_lo + cfmm_sizes[j]\n",
        "        cfmm_indices.append(range(idx_lo,idx_hi))\n",
        "        idx_lo = idx_hi\n",
        "\n",
        "    n_size = sum(cfmm_sizes)\n",
        "    assert idx_hi == n_size\n",
        "\n",
        "    return cfmm_indices  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mJ433awXwCbC"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "torch.manual_seed(42)\n",
        "random.seed(42)\n",
        "\n",
        "\n",
        "def test_apply_DYS():\n",
        "    ''' Apply DYS to toy problem and compare output to true solution.\n",
        "\n",
        "        Here we consider the 1D problem with \n",
        "\n",
        "        f(xi) = indicator for [1, 10], g(xi) = -6 * x, h(xi) = x^2 + 9.\n",
        "\n",
        "        Combining these gives the overall problem\n",
        "\n",
        "        min (x - 3)^2   s.t.   1 <= x <= 10,\n",
        "\n",
        "        and xi is initialized to 15.\n",
        "    '''\n",
        "    tol_err = 1.0e-3\n",
        "\n",
        "    def prox_f_toy(xi, scalar):\n",
        "        return torch.clamp(xi, min=1.0, max=10.0)\n",
        "\n",
        "    def prox_g_toy(xi, scalar):\n",
        "        return xi + 6.0 * scalar\n",
        "\n",
        "    def grad_h_toy(xi):\n",
        "        return 2.0 * xi\n",
        "    \n",
        "    L = 2.0\n",
        "    alpha = 0.5 / L\n",
        "    xi_init = 15.0 * torch.ones(1, 1)\n",
        "    xi_opt = 3.0 * torch.ones(1, 1)\n",
        "    xi_sol, _ = apply_DYS(prox_f_toy, prox_g_toy, grad_h_toy, xi_init, alpha)\n",
        "    err = torch.norm(xi_sol - xi_opt)  \n",
        "    assert err <= tol_err\n",
        "\n",
        "\n",
        "def test_prox_H():\n",
        "    ''' Check if projection of batch of vectors is in hyperplane is feasible.\n",
        "\n",
        "        Proximal is feasible if linear equation is satisfied (to numerical\n",
        "        precision) for CFMMs that are defined using weighted geometric means.\n",
        "        For the remaining arithmetic means, the proximal should give apply the\n",
        "        identity operation.\n",
        "    '''\n",
        "    n_batches = 20\n",
        "    n_cfmms = 10\n",
        "    tol_feas = 1.0e-6\n",
        "    cfmm_sizes = [random.randint(2, 10) for _ in range(n_cfmms)]\n",
        "    cfmm_indices = get_cfmm_indices(cfmm_sizes)\n",
        "    n_size = sum(cfmm_sizes)\n",
        "\n",
        "    v = torch.randn(n_size, n_batches)\n",
        "    w = torch.rand(n_size, 1)\n",
        "    d = torch.rand(n_size, 1)\n",
        "    delta = 0.05 * torch.rand(n_cfmms, 1) \n",
        "    cfmm_types = [torch.randint(2, (1,)) for _ in range(n_cfmms)]\n",
        "    \n",
        "    prox = prox_H(v, w, d, delta, cfmm_indices, cfmm_types)  \n",
        "\n",
        "    feasible = []\n",
        "    for j, idx in enumerate(cfmm_indices):\n",
        "        cfmm_geometric = bool(cfmm_types[j].numpy()) \n",
        "        if cfmm_geometric:\n",
        "            wt = w[idx, :].permute(1,0)\n",
        "\n",
        "            b = torch.log(1 + delta[j]) + torch.mm(wt, torch.log(d[idx, :])) \n",
        "            res = torch.mm(wt, prox[idx, :]) - b \n",
        "            rel_res = torch.mean(res / torch.norm(prox[idx, :], dim=0))  \n",
        "            feasible.append(bool(rel_res <= tol_feas))\n",
        "        else:\n",
        "            rel_res = torch.mean(torch.norm(prox[idx, :] - v[idx, :], dim=0)) \n",
        "            feasible.append(bool(rel_res <= tol_feas)) \n",
        "\n",
        "    assert all(feasible) \n",
        "\n",
        "def test_prox_A():\n",
        "    ''' Check if projection of batch of vectors is onto halfspace is feasible.\n",
        "\n",
        "        Proximal is feasible if linear inequality is satisfied (to numerical\n",
        "        precision) for CFMMs that are defined using weighted arithmetic means.\n",
        "        For the remaining geometric means, the proximal should give apply the\n",
        "        identity operation.\n",
        "    '''\n",
        "    n_batches = 20\n",
        "    n_cfmms = 10\n",
        "    tol_feas = 1.0e-6\n",
        "    cfmm_sizes = [random.randint(2, 10) for _ in range(n_cfmms)]\n",
        "    cfmm_indices = get_cfmm_indices(cfmm_sizes)\n",
        "    n_size = sum(cfmm_sizes)\n",
        "\n",
        "    v = torch.randn(n_size, n_batches).to(device)\n",
        "    w = torch.rand(n_size, 1).to(device)\n",
        "    d = torch.rand(n_size, 1).to(device)\n",
        "    delta = 0.05 * torch.rand(n_cfmms, 1).to(device)\n",
        "    cfmm_types = [torch.randint(2, (1,)).to(device) for _ in range(n_cfmms)]\n",
        "    \n",
        "    prox = prox_A(v, w, d, delta, cfmm_indices, cfmm_types)  \n",
        "\n",
        "    feasible = []\n",
        "    for j, idx in enumerate(cfmm_indices):\n",
        "        cfmm_arithmetic = not bool(cfmm_types[j].to('cpu').numpy()) \n",
        "        if cfmm_arithmetic:\n",
        "            wt = w[idx, :].permute(1,0)\n",
        "\n",
        "            b = delta[j] * torch.mm(wt, d[idx, :]) \n",
        "            res = torch.clamp(torch.mm(wt, prox[idx, :]) - b, max=0.0) \n",
        "            rel_res = torch.mean(res / torch.norm(prox[idx, :], dim=0))  \n",
        "            feasible.append(bool(rel_res <= tol_feas))\n",
        "        else:\n",
        "            rel_res = torch.mean(torch.norm(prox[idx, :] - v[idx, :], dim=0)) \n",
        "            feasible.append(bool(rel_res <= tol_feas)) \n",
        "\n",
        "    assert all(feasible) \n",
        "\n",
        "\n",
        "def test_prox_R():\n",
        "    ''' Check if projection onto {v = A * (Gamma * x - y)} is feasible.\n",
        "\n",
        "        This test requires the creation of a few mock CFMMs, and so matrices\n",
        "        A from the global coordinates to the local CFMM coordinates are needed.\n",
        "        First the number of tokens in each CFMM is randomly chosen between 2 and\n",
        "        the global size. Having this, a binary matrix A is constructed using\n",
        "        Bernoulli distributions (violating actual A structure, but close). \n",
        "    '''\n",
        "    tol_feas = 1.0e-6    \n",
        "    n_batches = 20\n",
        "    n_cfmms = 10\n",
        "    n_tokens = 10\n",
        "    cfmm_sizes = [random.randint(2, n_tokens) for _ in range(n_cfmms)]\n",
        "    cfmm_indices = get_cfmm_indices(cfmm_sizes)\n",
        "    n_size = sum(cfmm_sizes)\n",
        "\n",
        "    B = [torch.rand(cfmm_sizes[j], n_tokens) for j in range(n_cfmms)] \n",
        "    A = [torch.bernoulli(B[j]).to(device) for j in range(n_cfmms)]\n",
        "    A = get_block_diag(A).to(device)\n",
        "\n",
        "    Gamma = [0.97 * torch.eye(cfmm_sizes[j]) for j in range(n_cfmms)]  \n",
        "    Gamma = get_block_diag(Gamma).to(device) \n",
        "\n",
        "    v = torch.randn(n_size, n_batches).to(device)\n",
        "    x = torch.randn(n_cfmms * n_tokens, n_batches).to(device)  \n",
        "    y = torch.randn(n_cfmms * n_tokens, n_batches).to(device)\n",
        "\n",
        "    prox_v, prox_x, prox_y = prox_R(v, x, y, A, Gamma)\n",
        "\n",
        "    GAx = torch.mm(Gamma, torch.mm(A, prox_x))\n",
        "    Ay = torch.mm(A,prox_y)\n",
        "    res = torch.norm(prox_v - (GAx - Ay), dim=0)\n",
        "    rel_res = torch.mean(res / torch.norm(prox_v, dim=0))\n",
        "    feasible = bool(rel_res <= tol_feas)\n",
        " \n",
        "    assert feasible\n",
        "\n",
        "\n",
        "def test_prox_P():\n",
        "    ''' Check whether projection satisfies optimality condition.\n",
        "\n",
        "        The projection is a solution...\n",
        "    '''\n",
        "    n_batches = 40\n",
        "    n_size = 7\n",
        "    tol_feas = 1.0e-2\n",
        "    \n",
        "    v = torch.randn(n_size, n_batches)\n",
        "    z = torch.randn(n_size, n_batches)\n",
        "    d = torch.randn(n_size, n_batches)\n",
        "\n",
        "    prox_v, prox_z = prox_P(v, z, d)\n",
        "\n",
        "    indices = v + d < torch.exp(z) \n",
        "    pv = prox_v[indices]\n",
        "    vv = v[indices]\n",
        "    zz = z[indices]\n",
        "    dd = d[indices]\n",
        "    \n",
        "    res = (pv + dd) * (pv - vv) + torch.log(pv + dd) - zz\n",
        "    res = torch.mean(torch.abs(res))\n",
        "    feasible = bool(res <= tol_feas)\n",
        " \n",
        "    assert feasible"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "id": "TiuFN2Xc8Ks-",
        "outputId": "00ebdcdc-3f86-4b71-9c9f-6d92e3940ada"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-534319815045>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtest_apply_DYS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtest_prox_A\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mtest_prox_H\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mtest_prox_P\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-4684df0a2ab5>\u001b[0m in \u001b[0;36mtest_prox_A\u001b[0;34m()\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0mcfmm_types\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_cfmms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m     \u001b[0mprox\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprox_A\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfmm_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfmm_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0mfeasible\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-88ac0cae8cc8>\u001b[0m in \u001b[0;36mprox_A\u001b[0;34m(v, w, d, delta, geo_indices, cfmm_type)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;31m# d = [11, batch size]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mdd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdelta\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0;31m#dd = torch.cat([delta[j] * d[idx, :] for j, idx in enumerate(geo_indices)],\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;31m#               dim=0).to(device)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (10) must match the size of tensor b (49) at non-singleton dimension 0"
          ]
        }
      ],
      "source": [
        "#@title\n",
        "\n",
        "test_apply_DYS()\n",
        "test_prox_A()\n",
        "test_prox_H()\n",
        "test_prox_P()\n",
        "test_prox_R()\n",
        "print('All Pytests pass.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4kdgCzG0i-a"
      },
      "source": [
        "## Pytorch Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4s9jdyJX0j82"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class CfmmTradeModel(nn.Module):\n",
        "    ''' Implicit L2O model for trading cryptoassets.\n",
        "    '''\n",
        "    def __init__(self, w, A, p, cfmm_type, delta, Gamma, geo_indices):\n",
        "        super(CfmmTradeModel, self).__init__()\n",
        "        self.A = A.to(device)\n",
        "        self.AA = torch.mm(self.A.permute(1, 0), self.A)\n",
        "        self.W = nn.Parameter(torch.rand(A.shape[0], A.shape[0]).to(device))\n",
        "\n",
        "        self.mat1 = nn.Parameter(torch.randn(A.shape[0], A.shape[0]).to(device))        \n",
        "        self.mat2 = nn.Parameter(torch.randn(A.shape[0], A.shape[0]).to(device))\n",
        "        self.bias1 = nn.Parameter(torch.randn(A.shape[0],1).to(device))\n",
        "        self.bias2 = nn.Parameter(torch.randn(A.shape[0],1).to(device))\n",
        "        self.leaky_relu = nn.LeakyReLU(0.1)\n",
        "        self.tanh = nn.Tanh()\n",
        "        self.relu = nn.ReLU()\n",
        "        \n",
        "        self.w = w.to(device)\n",
        "        # self.delta = delta.to(device)\n",
        "        #self.delta = torch.ones(delta.shape).to(device)\n",
        "        #self.delta_scale = nn.Parameter(-3 * torch.ones(1).to(device))\n",
        "\n",
        "        self.delta = nn.Parameter(-3 * torch.ones(delta.shape).to(device))\n",
        "\n",
        "        self.L = None\n",
        "        self.psi_mean = 0\n",
        "        self.cfmm_types = cfmm_types\n",
        "        self.Gamma = Gamma.to(device)\n",
        "        self.p = p.to(device)\n",
        "        self.geo_indices = geo_indices\n",
        "        \n",
        "\n",
        "        self.local_size = self.A.shape[0]\n",
        "        self.global_size = self.A.shape[1] \n",
        "\n",
        "\n",
        "    def device(self) -> str:\n",
        "        return next(self.parameters()).data.device\n",
        "\n",
        "    def psi(self, d, tol=1.0e-1):\n",
        "        ''' Give weight for risk term in utility\n",
        "\n",
        "            Note: Since phi is used in the utility, we must ensure its output\n",
        "                  does not result in a trade transacted with a coin that is not\n",
        "                  available for trade on a given CFMM. This is accounted for\n",
        "                  by mapping psi from global coordinates to local coordinates,\n",
        "                  and then back to global coordinates via A and its transpose.\n",
        "                  This process \"zeros out\" any token values that are \"invalid.\"\n",
        "        '''\n",
        "        sigmoid = nn.Sigmoid()\n",
        "        risk_weight = torch.mm(self.mat1, d) + self.bias1\n",
        "        risk_weight = self.tanh(torch.mm(self.mat2, risk_weight) + self.bias2) \n",
        "        return sigmoid(risk_weight).to(device)\n",
        "\n",
        "    def zero_weights(self):       \n",
        "        n_tokens = int(self.A.shape[1] / len(self.cfmm_types))\n",
        "        W_zero = torch.zeros(self.W.data.shape).to(device)          \n",
        "\n",
        "        idx_lo = 0\n",
        "        for j, n_tokens_loc in enumerate(self.geo_indices):\n",
        "            idx_hi = idx_lo + len(n_tokens_loc)\n",
        "            W_zero[idx_lo:idx_hi, idx_lo:idx_hi] = self.W.data[idx_lo:idx_hi,\n",
        "                                                               idx_lo:idx_hi]\n",
        "            idx_lo = idx_hi\n",
        "                \n",
        "        self.W.data = W_zero\n",
        "\n",
        "\n",
        "    def forward(self, d, fxd_pt_tol=1.0e-3, max_iters=int(2.0e3), \n",
        "                verbose=False, return_obj=False, analytic=False):\n",
        "        ''' Apply Davis-Yin Splitting to minimize f + g + h\n",
        "\n",
        "            Convergence is measured by fixed point residual.\n",
        "\n",
        "            XXX - Force L to be actual Lipschitz constant\n",
        "\n",
        "            Note: Assumes input d = [batch_size, reserves_size]\n",
        "        '''\n",
        "        assert torch.is_tensor(d) \n",
        "\n",
        "        self.zero_weights()\n",
        "\n",
        "        # local coordinate sizes\n",
        "        v = torch.zeros(self.local_size, d.shape[1]).to(device)\n",
        "        z = torch.zeros(self.local_size, d.shape[1]).to(device)\n",
        "\n",
        "        # global coordinate sizes\n",
        "        x = torch.zeros(self.global_size, d.shape[1]).to(device)  \n",
        "        y = torch.zeros(self.global_size, d.shape[1]).to(device) \n",
        "        \n",
        "        zeta = torch.cat((v, x, y, z), dim=0)\n",
        "\n",
        "        # delta = torch.exp(self.delta_scale * self.delta)\n",
        "        delta = torch.exp(self.delta)\n",
        "\n",
        "        def prox_f_m(xi, alpha=None): \n",
        "            return prox_f_model(xi, d, self.w, delta, self.geo_indices,\n",
        "                                self.cfmm_types)\n",
        "\n",
        "        def prox_g_m(xi, alpha=None):\n",
        "            return prox_g_model(xi, d, self.w, delta, self.geo_indices,\n",
        "                                self.cfmm_types, self.A,\n",
        "                                self.Gamma)   \n",
        "\n",
        "        # psi = self.psi(d) if not analytic else 0.0 * self.psi(d)\n",
        "        # self.psi_mean = torch.mean(psi).detach().to('cpu').numpy()\n",
        "        \n",
        "        psi = torch.ones(1).to(device) if not analytic else torch.zeros(1).to(device)\n",
        "\n",
        "\n",
        "        W = torch.abs(self.W)\n",
        "        # W = torch.zeros(self.W.shape).to(device)\n",
        "        # if not analytic:\n",
        "        #     W[self.W != 0] = torch.abs(self.W[self.W != 0])\n",
        "        \n",
        "        # W = torch.exp(self.W) if not analytic else torch.zeros(self.W.shape).to(device)     \n",
        "\n",
        "        def grad_h_m(xi):  \n",
        "            return grad_h(xi, self.p, W, self.A, \n",
        "                          psi,\n",
        "                          len(self.cfmm_types)) \n",
        "        \n",
        "\n",
        "        WA = torch.mm(W, self.A).to(device)\n",
        "        AWWA = torch.mm(WA.permute(1,0), WA).to(device)\n",
        "\n",
        "        # self.L = 1.0e-5 + torch.linalg.matrix_norm(AWWA, ord=2)\n",
        "        \n",
        "        # self.psi_scaling =  if not analytic else 1.0\n",
        "        self.L = 1.0e-1 + torch.norm(AWWA) * torch.max(psi)\n",
        "        alpha = 1.99 / self.L  \n",
        "\n",
        "        with torch.no_grad(): \n",
        "            # Bound singular values to unity and zero out off block diagonals\n",
        "            # self.zero_weights()\n",
        "            # u, s, v = torch.svd(self.W.data)\n",
        "            # s = s / s[0]\n",
        "            # #s[s > 1.0] = torch.ones(s[s > 1].shape).to(device)\n",
        "            # self.W.data = torch.mm(torch.mm(u, torch.diag(s)), v.t())\n",
        "\n",
        "            #alpha = min(1.0e2, 0.99 / (float(torch.max(psi_val).cpu() * self.L)))\n",
        "            # alpha = min(1.0e2, 0.99 / self.L)\n",
        "\n",
        "            # print('alpha = ', alpha)\n",
        "     \n",
        "            xi, zeta = apply_DYS(prox_f_m, prox_g_m, grad_h_m, zeta, alpha, \n",
        "                                fxd_pt_tol=fxd_pt_tol, max_iters=max_iters,\n",
        "                                verbose=verbose)\n",
        "\n",
        "        # Attach gradients for final iterations\n",
        "        xi, _ = apply_DYS(prox_f_m, prox_g_m, grad_h_m, zeta, alpha, \n",
        "                          fxd_pt_tol=fxd_pt_tol, max_iters=1,\n",
        "                          verbose=verbose)        \n",
        "        q = A.shape[0]\n",
        "        m = A.shape[1]\n",
        "\n",
        "        x_idx = range(q, q+m)\n",
        "        y_idx = range(q+m,q+2*m)        \n",
        "        x = xi[x_idx, :]\n",
        "        y = xi[y_idx, :]\n",
        "        \n",
        "        # Post conditions\n",
        "        tender_nonnegative  = (x >= 0).to('cpu').numpy().all()\n",
        "        receive_nonnegative = (y >= 0).to('cpu').numpy().all()\n",
        "        assert tender_nonnegative\n",
        "        assert receive_nonnegative\n",
        "\n",
        "        check_violation(x, y, d, self.w, self.A, self.Gamma, geo_indices,\n",
        "                        self.cfmm_types, verbose=verbose,\n",
        "                        tol_err=1.0e-1)\n",
        "\n",
        "        return x.permute(1,0), y.permute(1,0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3OEAD2yzDJvk"
      },
      "source": [
        "# Toy Crypto Trade Problem\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iGXYeZpIJeM7"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_NGoX4sTfsn"
      },
      "source": [
        "## Check trade violation\n",
        "\n",
        "This function is used to check whether a given trade is \"valid\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nWVURRPeTjF_"
      },
      "outputs": [],
      "source": [
        "def check_violation(x, y, d, w, A, Gamma, geo_indices, cfmm_type, \n",
        "                    tol_err=1.0e-2, verbose=False):\n",
        "\n",
        "    assert torch.is_tensor(x)\n",
        "    assert torch.is_tensor(y)\n",
        "    assert torch.is_tensor(d)\n",
        "    assert torch.is_tensor(w)\n",
        "    assert torch.is_tensor(A)\n",
        "    assert torch.is_tensor(Gamma)        \n",
        "    violation = []\n",
        "\n",
        "    num_samples = x.shape[1] \n",
        "    for s in range(num_samples):\n",
        "        for i, j in enumerate(geo_indices):\n",
        "            geometric = cfmm_type[i]\n",
        "            G = Gamma[j[0]:(1+j[-1]), j[0]:(1+j[-1])]\n",
        "            if geometric:\n",
        "                v = torch.log(d[j, :] +  torch.mm(G, torch.mm(A[j, :], x)) - torch.mm(A[j, :], y))\n",
        "                new_val = torch.mm(w[j, :].permute(1,0), v).to('cpu').detach().numpy()[0][s] \n",
        "                ref_val = torch.mm(w[j, :].permute(1,0), torch.log(d[j, :])).to('cpu').detach().numpy()[0][s] \n",
        "            else:\n",
        "                v = d[j] + torch.mm(G, torch.mm(A[j, :], x)) - torch.mm(A[j, :], y)\n",
        "                new_val = torch.mm(w[j, :].permute(1,0), v).to('cpu').detach().numpy()[0][s]\n",
        "                ref_val = torch.mm(w[j, :].permute(1,0), d[j]).to('cpu').detach().numpy()[0][s]        \n",
        "            \n",
        "            err = ref_val - new_val\n",
        "            if verbose:\n",
        "                msg = 'Rel error in phi[{:d}](trade) = {:0.4f}%'\n",
        "                print(msg.format(i, 100.0 * err / ref_val))\n",
        "            assert err <= tol_err * ref_val   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQT0WdpbTm64"
      },
      "source": [
        "(First we include a snippet of code for printing trades)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "M4JP9pS_JWyj"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "\n",
        "def print_trade(x, y):\n",
        "    for j, _ in enumerate(x):\n",
        "        print('Trades with CFMM', j)\n",
        "        for i in range(x[j].shape[0]): \n",
        "            val = float(x[j][i].numpy()) \n",
        "            print('Tendered {:.2f} of token {:d}.'.format(val, i))\n",
        "        for i in range(y[j].shape[0]):\n",
        "            val = float(y[j][i].numpy()) \n",
        "            print('Received {:.2f} of token {:d}.'.format(val, i))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zSwaRFfoJibG"
      },
      "source": [
        "## Toy Problem\n",
        "\n",
        "The following snippet is used to show the implementation of the model (without training and without noise)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NT1wk0pfDVxq"
      },
      "outputs": [],
      "source": [
        "# Tolerances for each CFMM\n",
        "deltas = 1.0e-2 * torch.ones(5,1).to(device) #[torch.zeros(1).to(device) for delta in range(5)]\n",
        "cfmm_sizes = [3, 2, 2, 2, 2]\n",
        "geo_indices = get_cfmm_indices(cfmm_sizes)\n",
        "\n",
        "# Trade fee parameters in each CFMM\n",
        "gammas = [0.98, 0.99, 0.98, 0.99, 0.98]\n",
        "Gamma = [gamma * torch.eye(cfmm_sizes[j]).to(device)\n",
        "         for j, gamma in enumerate(gammas)]\n",
        "Gamma = get_block_diag(Gamma).to(device)\n",
        "\n",
        "# Weights for the modified means in each CFMM\n",
        "w1 = torch.tensor([[0.2], [0.3], [0.5]]).to(device)\n",
        "w2 = torch.tensor([[0.4], [0.6]]).to(device)\n",
        "w3 = torch.tensor([[0.5], [0.5]]).to(device)\n",
        "w4 = torch.tensor([[0.6], [0.4]]).to(device)\n",
        "w5 = torch.tensor([[0.6], [0.4]]).to(device)\n",
        "w = torch.cat((w1, w2, w3, w4, w5), dim=0).to(device)\n",
        "\n",
        "# Label for which CFMMs uses geometric means (otherwise use arithmetic)\n",
        "cfmm_types = [True, True, True, True, False]\n",
        "cfmm_types = [float(cfmm_type) * torch.ones(1).to(device) for cfmm_type in cfmm_types] \n",
        "\n",
        "# Transformations from global to local coordinates of each CFMM\n",
        "A1 = torch.tensor([[1.0, 0.0, 0.0], [0.0, 1.0, 0.0], [0.0, 0.0, 1.0]]).to(device)\n",
        "A2 = torch.tensor([[1.0, 0.0, 0.0], [0.0, 1.0, 0.0]]).to(device)\n",
        "A3 = torch.tensor([[0.0, 1.0, 0.0], [0.0, 0.0, 1.0]]).to(device)\n",
        "A4 = torch.tensor([[1.0, 0.0, 0.0], [0.0, 0.0, 1.0]]).to(device)\n",
        "A5 = torch.tensor([[1.0, 0.0, 0.0], [0.0, 0.0, 1.0]]).to(device)\n",
        "A = [A1, A2, A3, A4, A5]\n",
        "A = get_block_diag(A).to(device)\n",
        "print('A = ', A)\n",
        "print('A.shape = ', A.shape)\n",
        "\n",
        "# Define intrinsic value of assets\n",
        "p = torch.tensor([[1.0], [1.0], [1.0]]).to(device)\n",
        "\n",
        "# Trade model for CFMM network\n",
        "the_model = CfmmTradeModel(w, A, p, cfmm_types, deltas, Gamma, geo_indices)\n",
        "print('model loaded successfully')\n",
        "\n",
        "# Sample data for reserves in CFMM network\n",
        "d1 = torch.tensor([[5.0], [7.3], [12.5]]).to(device)\n",
        "d2 = torch.tensor([[10.0], [4.7]]).to(device)\n",
        "d3 = torch.tensor([[5.5], [7.4]]).to(device)\n",
        "d4 = torch.tensor([[4.6], [14.9]]).to(device)\n",
        "d5 = torch.tensor([[7.6], [5.4]]).to(device)\n",
        "d = torch.cat((d1, d2, d3, d4, d5), dim=0).to(device)\n",
        "#d = d.permute(1,0).clone()\n",
        "\n",
        "# Optimal trade for provided data\n",
        "x, y = the_model(d, verbose=True)\n",
        "\n",
        "print('x = ', x)\n",
        "print('y = ', y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKobKkWBmyQl"
      },
      "source": [
        "## Price Generation\n",
        "\n",
        "$$ \\dfrac{p_j}{p_k} = \\dfrac{\\nabla_j \\phi(d)}{\\nabla_k \\phi(d)}.$$\n",
        "\n",
        "For geometric CFMMs, \n",
        "\n",
        "$$ \\nabla_\\ell \\phi(d) = \\dfrac{w_\\ell}{d_\\ell} \\cdot \\phi(d).$$\n",
        "\n",
        "which implies\n",
        "\n",
        "$$ \\dfrac{p_j}{p_k} = \\dfrac{w_j / d_j}{w_k / d_k} = \\dfrac{w_j}{w_k}\\cdot \\dfrac{d_k}{d_j}.$$\n",
        "\n",
        "Thus, for a known prices $p_j$ and $p_k$, weights $w_j$ and $w_k$, and reserves $d_k$, we can find the amount of reserves for the $j$-th token; namely,\n",
        "\n",
        "$$ d_j = \\dfrac{w_j p_k d_k}{w_k p_j}.$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0H2hdfB5mz8i"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from torch.utils.data.dataset import random_split\n",
        "\n",
        "rel_token_vals_ave = torch.tensor([[1.0], [1.9], [0.5]])\n",
        "res_ave = [50.0, 30.0, 23.5, 35.7, 46.9]\n",
        "the_model.p = rel_token_vals_ave\n",
        "\n",
        "\n",
        "def get_token_val_sample(rel_vals, var):\n",
        "    sample = torch.tensor([[(1.0 + var * torch.randn(1)) * val.numpy()]\n",
        "              for _, val in enumerate(rel_vals)])\n",
        "    return sample\n",
        "\n",
        "def create_loader(A, n_tokens, cfmm_indices, train_size=5000, test_size=500,\n",
        "                  train_batch_size=100, test_batch_size=500):\n",
        "\n",
        "    var_per = 1.0e-1\n",
        "   \n",
        "    torch.manual_seed(2022)\n",
        "    d = []\n",
        "    \n",
        "    batch_size = train_size + test_size\n",
        "\n",
        "    for j, idx in enumerate(cfmm_indices): \n",
        "        \n",
        "        A_block = A[idx, j*n_tokens:(j+1)*n_tokens]\n",
        "\n",
        "        loc_rel_token_vals = torch.mm(A_block.to('cpu'), rel_token_vals_ave)\n",
        "\n",
        "        rel_token_vals_sample = loc_rel_token_vals\n",
        "        for k in range(batch_size):\n",
        "            new_sample = get_token_val_sample(loc_rel_token_vals, var_per)\n",
        "            if k > 0:\n",
        "                rel_token_vals_sample = torch.cat((rel_token_vals_sample, new_sample), dim=1)\n",
        "            else:\n",
        "                rel_token_vals_sample = new_sample \n",
        "\n",
        "        num_tokens = len(idx)\n",
        "        reserves = torch.zeros(num_tokens, batch_size)\n",
        "        for t in range(num_tokens):\n",
        "            res_samples = (1.0 + var_per * torch.randn(batch_size)) * res_ave[j]\n",
        "\n",
        "            reserves[t, :] = float(w[idx, :][t]) * rel_token_vals_sample[0, :]\n",
        "            reserves[t, :] *= res_samples \n",
        "            reserves[t, :] /= (float(w[idx, :][0]) * rel_token_vals_sample[t, :])\n",
        "\n",
        "        reserves = torch.tensor(reserves)\n",
        "        d.append(reserves)\n",
        "\n",
        "    d_ten = d[0] \n",
        "    for idx, _ in enumerate(d):\n",
        "        if idx > 0:\n",
        "            d_ten = torch.cat((d_ten, d[idx]), dim=0) \n",
        "\n",
        "    d_ten = d_ten.permute(1,0)  \n",
        "\n",
        "    # --------------------------------------------------------------------------\n",
        "    # Analytic predictions with no noise\n",
        "    # --------------------------------------------------------------------------\n",
        "    # anal_model = CfmmTradeModel(w, A, p, cfmm_types, deltas, Gamma, geo_indices) \n",
        "    # anal_model.eval()\n",
        "    # with torch.no_grad():\n",
        "    #     for j, val in enumerate(anal_model.W): \n",
        "    #         anal_model.W[j][0]= torch.zeros(val[0].shape)           \n",
        "    \n",
        "    # x_true, y_true = anal_model(d_ten.permute(1,0).to(device),\n",
        "    #                             max_iters=int(1.0e4))\n",
        "    # x_true = x_true.detach()\n",
        "    # y_true = y_true.detach()\n",
        "    # --------------------------------------------------------------------------\n",
        "    # --------------------------------------------------------------------------\n",
        "    std = 1.0e-3 * torch.rand(d_ten.shape[0], 1)\n",
        "    std = std * torch.ones(d_ten.shape)  \n",
        "    noise = torch.normal(mean=torch.zeros(d_ten.shape), std=std) \n",
        "    d_obs = (1.0 + noise) * d_ten \n",
        "    \n",
        "    dataset = TensorDataset(d_obs.to(device), d_ten.to(device))\n",
        "    # dataset = TensorDataset(d_obs.to(device), d_ten.to(device), x_true.to(device), y_true.to(device))\n",
        "\n",
        "    train_data, test_data = random_split(dataset, [train_size,\n",
        "                                                   test_size])\n",
        "    loader_train = DataLoader(dataset=train_data,\n",
        "                              batch_size=train_batch_size, shuffle=True)\n",
        "    loader_test = DataLoader(dataset=test_data,\n",
        "                             batch_size=test_batch_size, shuffle=False)\n",
        "\n",
        "    return loader_train, loader_test\n",
        "\n",
        "def convert_to_tensor(x_list):\n",
        "    x_ten = x_list[0]\n",
        "    x_ten = x_list[0]\n",
        "    for idx, val in enumerate(x_list):\n",
        "        if idx > 0:\n",
        "            x_ten = torch.cat((x_ten, val), dim=0)\n",
        "    x_ten = x_ten.permute(1,0)  \n",
        "    return x_ten  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7VkEq89MWGJ"
      },
      "source": [
        "## Correct Trade Errors\n",
        "\n",
        "Define\n",
        "\n",
        "$$ \\theta(\\tau) \\triangleq \\phi(d + \\Gamma A x - A(y - \\tau p)) - \\phi(d).$$\n",
        "\n",
        "Use Newton\n",
        "\n",
        "$$ \\tau_{k+1} = \\tau_k - \\dfrac{ \\theta(\\tau_k)}{\\theta'(\\tau_k)}.$$\n",
        "\n",
        "Let $q = d + \\gamma x - y$. For geommetric CFMMs, we use\n",
        "\n",
        "$$ \\tilde{\\phi}(v) \\triangleq \\left< w, \\ln(v)\\right>$$\n",
        "\n",
        "so that\n",
        "\n",
        "$$ \\theta'(\\tau) = \\left< \\nabla \\tilde{\\phi}(z + \\tau A p),A p\\right> = \\tilde{\\phi}(z+\\tau A p) \\left<\\frac{w}{z+\\tau A p}, A p\\right>.$$\n",
        "\n",
        "Meanwhile, for weighted arithmetic mean CFMMs,\n",
        "\n",
        "$$ \\tilde{\\phi}(v) \\triangleq \\left< w, v\\right>,$$\n",
        "\n",
        "for which\n",
        "\n",
        "$$ \\theta'(\\tau) = \\left< \\nabla \\tilde{\\phi}(z + \\tau A p), Ap\\right> =  \\left<w, Ap\\right>.$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vXSgGTUVMX2e"
      },
      "outputs": [],
      "source": [
        "\n",
        "## REPLACE THIS WITH BISECTION METHOD\n",
        "\n",
        "def correct_trade(x, y, d, p, A, Gamma, ww, geo_indices, cfmm_type, n_tokens, newton_iters=200):\n",
        "    y_correct = []\n",
        "\n",
        "    y_correct = torch.zeros(y.shape).to(device)\n",
        "\n",
        "    for j, idx in enumerate(geo_indices): \n",
        "        tau = 0.0\n",
        "        #iter = 0\n",
        "        #invalid_trade = True\n",
        "\n",
        "        #while iter < newton_iters and invalid_trade:\n",
        "        #    iter = iter + 1\n",
        "        for iter in range(newton_iters): \n",
        "            \n",
        "            geometric = cfmm_type[j]\n",
        "\n",
        "            G = Gamma[idx[0]:(1+idx[-1]), idx[0]:(1+idx[-1])] \n",
        "            if geometric:\n",
        "                 \n",
        "                ytp = y[n_tokens*j:(j+1)*n_tokens, :] - tau * p\n",
        "                ytp = ytp.to(device)\n",
        "                Aytp =  torch.mm(A[idx, n_tokens*j:(j+1)*n_tokens], ytp).to(device)\n",
        "                Ax = torch.mm(A[idx, :], x).to(device)\n",
        "                GAxAytp =  (torch.mm(G, Ax) - Aytp).to(device) \n",
        "                d_block = d[idx, :].to(device)\n",
        "\n",
        "                v = torch.log(d_block + GAxAytp).to(device)   \n",
        "                v = torch.clamp(v, min=1.0e-6).to(device) \n",
        "                \n",
        "                phi_z = torch.mm(ww[idx, :].permute(1,0), v)[0]\n",
        "                phi_d = torch.mm(ww[idx, :].permute(1,0), torch.log(d[idx, :]))[0]\n",
        "\n",
        "                theta_z = phi_z - phi_d\n",
        "\n",
        "                # invalid_trade = (theta_z < 0).any()\n",
        "\n",
        "                dot_product = torch.mm(torch.mm(p.permute(1,0), A[idx, n_tokens*j:(j+1)*n_tokens].permute(1,0)), ww[idx, :] / v)\n",
        "\n",
        "                if iter < 20:\n",
        "                    tau =  tau - (0.05 / float(iter + 1)) * theta_z\n",
        "                else:\n",
        "                    tau = tau - theta_z / (phi_z * dot_product)\n",
        "            else:\n",
        "                v = d[idx, :] +  torch.mm(G, torch.mm(A[idx, :], x)) - torch.mm(A[idx, n_tokens*j:(j+1)*n_tokens], y[n_tokens*j:(j+1)*n_tokens, :] - tau * p)\n",
        "                theta_z = torch.mm(ww[idx, :].permute(1,0), v - d[idx, :])\n",
        "\n",
        "                if iter < 20:\n",
        "                    tau = tau - (0.05 / float(iter + 1)) * theta_z \n",
        "                else:\n",
        "                    tau = tau - theta_z / torch.mm(ww[idx, :].permute(1,0), torch.mm(A[idx, n_tokens*j:(j+1)*n_tokens], p))                \n",
        "\n",
        "        y_block =  y[n_tokens*j:(j+1)*n_tokens, :] - tau * p\n",
        "        y_correct[n_tokens*j:(j+1)*n_tokens, :] = y_block\n",
        "\n",
        "    check_violation(x, y_correct, d, ww, A, Gamma, geo_indices, cfmm_types)\n",
        "    return x, y_correct"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QfCRFT4CVRbo"
      },
      "outputs": [],
      "source": [
        "def compute_energy(d, ww, A, geo_indices, cfmm_type):\n",
        "    ''' Get the energy violation of system\n",
        "    '''\n",
        "    energy = torch.zeros(len(geo_indices), d.shape[1]).to(device)\n",
        "\n",
        "    for j, idx in enumerate(geo_indices): \n",
        "        geometric = cfmm_type[j]\n",
        "\n",
        "        if geometric:\n",
        "            term = torch.mm(ww[idx, :].permute(1,0), torch.log(d[idx, :]))\n",
        "            energy[j, :] += torch.sum(torch.exp(term))\n",
        "        else: \n",
        "            energy[j, :] += torch.sum(torch.mm(ww[idx, :].permute(1,0), d[idx, :]))\n",
        "    return energy\n",
        "\n",
        "\n",
        "def get_violation(x, y, d, w, A, Gamma, geo_indices, cfmm_type):\n",
        "    relu = nn.ReLU()\n",
        "    energy_new = compute_energy(d + torch.mm(Gamma, torch.mm(A, x)) - torch.mm(A,y), w, A, geo_indices, cfmm_type)\n",
        "    energy_old = compute_energy(d, w, A, geo_indices, cfmm_type) \n",
        "    error = relu(energy_old - energy_new)\n",
        "\n",
        "    error_mean = torch.sum(torch.mean(error, dim=1))\n",
        "\n",
        "    error_rel = torch.sum(torch.mean(error, dim=1)) / torch.sum(torch.mean(energy_old))\n",
        "    return error_mean, error_rel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hFSZzPIyhVwZ"
      },
      "outputs": [],
      "source": [
        "def get_list_from_ten(d, w):\n",
        "    d_list = []\n",
        "    idx_lo = 0\n",
        "    for j, _ in enumerate(w):\n",
        "        idx_hi = idx_lo + w[j].shape[0]\n",
        "        d_list.append(d[:, idx_lo:idx_hi].permute(1,0))\n",
        "        idx_lo = idx_hi\n",
        "    return d_list\n",
        "\n",
        "def get_ten_from_list(d):\n",
        "    d_ten = torch.zeros(d[0].shape)\n",
        "\n",
        "    for j, val in enumerate(d):\n",
        "        d_ten = torch.cat((d_ten, val), dim=0)\n",
        "    return d_ten    \n",
        "    \n",
        "def utility(x, y, p):\n",
        "    n_cfmms = int(x.shape[0] / p.shape[0])\n",
        "    obj = torch.zeros(1, x.shape[1]).to(device)\n",
        "    for j in range(n_cfmms):\n",
        "        yx = (y - x).to(device)\n",
        "        obj = obj + torch.mm(p.permute(1,0), yx[j*p.shape[0]:(j+1)*p.shape[0]])\n",
        "    return obj    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23vBpSlZMsn3"
      },
      "source": [
        "## Train Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jl3pqSpwhfoa"
      },
      "outputs": [],
      "source": [
        "from prettytable import PrettyTable\n",
        "\n",
        "n_tokens = 3\n",
        "loader_train, loader_test = create_loader(A, n_tokens, geo_indices)\n",
        "num_epochs    = int(1.0e3)\n",
        "learning_rate = 5.0e-3\n",
        "optimizer     = torch.optim.Adam(the_model.parameters(), lr=learning_rate)\n",
        "lr_scheduler  = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5,\n",
        "                                                gamma=0.98)\n",
        "training_msg  = '[{:4d}] Contraint Error = {:6.2f}%'\n",
        "training_msg += '| loss = {:8.1e} | pred util = {:8.1e} | fro-norm = {:2.2e} '\n",
        "training_msg += '| psi = {:2.3e} | lr = {:2.2e}'\n",
        "\n",
        "MSE = nn.MSELoss()\n",
        "\n",
        "def model_params(net):\n",
        "    table = PrettyTable([\"Network Component\", \"# Parameters\"])\n",
        "    num_params = 0\n",
        "    for name, parameter in net.named_parameters():\n",
        "        if not parameter.requires_grad:\n",
        "            continue\n",
        "        table.add_row([name, parameter.numel()])\n",
        "        num_params += parameter.numel()\n",
        "    table.add_row(['TOTAL', num_params])\n",
        "    return table\n",
        "\n",
        "print(model_params(the_model))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1WdLT1z-MMat"
      },
      "outputs": [],
      "source": [
        "loss_ave = 0.0\n",
        "obj_ave = 0.0\n",
        " \n",
        "the_model.to(device)\n",
        "\n",
        "for epoch in range(num_epochs): \n",
        "    for d_obs, d_true in loader_train:\n",
        "        optimizer.zero_grad()\n",
        "        the_model.train() \n",
        "        x, y = the_model(d_obs.permute(1,0).to(device), max_iters=int(1.0e3))\n",
        "        \n",
        "        obj = torch.mean(utility(x.permute(1,0), y.permute(1,0), the_model.p.to(device)))\n",
        "        viol, rel_viol = get_violation(x.permute(1,0), y.permute(1,0),\n",
        "                                       d_true.permute(1,0), w, A, Gamma,\n",
        "                                       geo_indices, cfmm_types)\n",
        "        \n",
        "        loss = 1.0e-1 * (viol ** 2) - obj\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        loss_curr = loss.detach().item()\n",
        "        loss_ave *= 0.9\n",
        "        loss_ave += 0.1 * loss_curr if loss_ave != 0 else loss_curr     \n",
        "\n",
        "        W = torch.abs(the_model.W.data.clone()) \n",
        "\n",
        "        print(training_msg.format(epoch, 100 * rel_viol, loss_ave, obj,\n",
        "                                  torch.norm(W),\n",
        "                                  the_model.psi_mean,\n",
        "                                  optimizer.param_groups[0]['lr']\n",
        "                                  ))\n",
        "        print('delta = ', the_model.delta)\n",
        "    lr_scheduler.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6E1DTFH8RSIm"
      },
      "outputs": [],
      "source": [
        "print(the_model.delta)\n",
        "print(the_model.delta_scale)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1LoA5sZarvL9"
      },
      "source": [
        "Print of heatmap of matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lttzUJ0x8-I8"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "W = the_model.W.data.clone()\n",
        "W[W != 0] = torch.exp(W[W != 0])\n",
        "\n",
        "plt.imshow(W.to('cpu').detach().numpy(), interpolation='nearest')\n",
        "plt.colorbar()\n",
        "plt.show()\n",
        "\n",
        "# CONFUSION MATRIX?\n",
        "\n",
        "print(the_model.W.data.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ra8UAVbNrvLi"
      },
      "source": [
        "Load analytic model and set weights $W$ to be zero, *i.e.* no correction term."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D0J6csBVeEce"
      },
      "outputs": [],
      "source": [
        "# anal_model = CfmmTradeModel(w, A, p, cfmm_types, deltas, Gamma, geo_indices)\n",
        "# with torch.no_grad():\n",
        "#     for j, val in enumerate(anal_model.W): \n",
        "#         anal_model.W[j][0]= torch.zeros(val[0].shape)       "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QNRBmFxArmQ6"
      },
      "source": [
        "## Testing Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vzht3O11aLaJ"
      },
      "outputs": [],
      "source": [
        "# XXX - Loss Testing stuff....\n",
        "\n",
        "#for d_obs, d_true, x_true, y_true in loader_test:                        \n",
        "for d_obs, d_true in loader_test:   \n",
        "    the_model.eval() \n",
        "    x_l2o, y_l2o = the_model(d_obs.permute(1,0).to(device), max_iters=int(1e3))\n",
        "\n",
        "    x_anal, y_anal = the_model(d_obs.permute(1,0).to(device), max_iters=int(2e3),\n",
        "                               analytic=True)\n",
        "\n",
        "    # x_anal, y_anal = anal_model(d_obs.permute(1,0).to(device), max_iters=int(1e3))\n",
        "\n",
        "    # d_true = get_list_from_ten(d_true, w)\n",
        "\n",
        "    # x_l2o_corr, y_l2o_corr = correct_trade(x_l2o.permute(1,0),\n",
        "    #                                          y_l2o.permute(1,0), \n",
        "    #                                          d_true.permute(1,0), \n",
        "    #                                          the_model.p.to(device), A, Gamma, \n",
        "    #                                          w, geo_indices, cfmm_types,\n",
        "    #                                          n_tokens)\n",
        "    \n",
        "    # x_anal_corr, y_anal_corr = correct_trade(x_anal.permute(1,0),\n",
        "    #                                          y_anal.permute(1,0), \n",
        "    #                                          d_true.permute(1,0), \n",
        "    #                                          the_model.p.to(device), A, Gamma, \n",
        "    #                                          w, geo_indices, cfmm_types,\n",
        "    #                                          n_tokens)\n",
        "    \n",
        "    #y_ten_l2o = get_ten_from_list(y_l2o)\n",
        "    #y_corr_l2o = get_ten_from_list(y_corr_l2o)\n",
        "#mse = MSE(y_l2o, y_true) + MSE(x_l2o, x_true)\n",
        "#print('y_l2o = ', y_l2o)\n",
        "#print('y_true = ', y_true)\n",
        "#print('mse = ', mse)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r60PPX-rrf6G"
      },
      "source": [
        "### Plot Data for Figure 10 in paper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dKwVJRpaSVmk"
      },
      "outputs": [],
      "source": [
        "def check_constraints(x, y, d, w, A, Gamma, geo_indices, cfmm_type):\n",
        "    relu = nn.ReLU()\n",
        "    energy_new = compute_energy(d + torch.mm(Gamma, torch.mm(A, x)) - torch.mm(A,y), w, A, geo_indices, cfmm_type)\n",
        "    energy_old = compute_energy(d, w, A, geo_indices, cfmm_type) \n",
        "    constraint_viol = relu(energy_old - energy_new)\n",
        "    return constraint_viol"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BJICyW7rf5r9"
      },
      "outputs": [],
      "source": [
        "util_l2o = utility(x_l2o.to(device).permute(1,0), y_l2o.to(device).permute(1,0), the_model.p.to(device))\n",
        "\n",
        "print('util_l2o = ', util_l2o)\n",
        "constraint_viol = check_constraints(x_l2o.permute(1,0), y_l2o.permute(1,0),\n",
        "                                    d_true.permute(1,0), w, A, Gamma,\n",
        "                                    geo_indices, cfmm_types)\n",
        "\n",
        "constraint_viol = torch.sum(constraint_viol, dim=0, keepdim=True)\n",
        "util_l2o[constraint_viol > 0] = 0.0 * util_l2o[constraint_viol > 0] \n",
        "\n",
        "print('util_l2o = ', torch.mean(util_l2o))\n",
        "\n",
        "\n",
        "util_anal = utility(x_anal.permute(1,0), y_anal.permute(1,0), the_model.p.to(device))\n",
        "constraint_viol = check_constraints(x_anal.permute(1,0), y_anal.permute(1,0),\n",
        "                                    d_true.permute(1,0), w, A, Gamma,\n",
        "                                    geo_indices, cfmm_types)\n",
        "\n",
        "constraint_viol = torch.sum(constraint_viol, dim=0, keepdim=True)\n",
        "print('pre_anal = ', util_anal)\n",
        "\n",
        "util_anal[constraint_viol > 0] = 0.0 * util_anal[constraint_viol > 0] \n",
        "\n",
        "\n",
        "print('util_anal = ', torch.mean(util_anal))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "zRmX2Fex4dGz",
        "8_MjqeO-gGkg",
        "qLD8aJL6_sow",
        "jmyvVM0-B-8_",
        "jo6oUF-2P7n8",
        "iT7sYwCJA9Zx",
        "AYZkbVmHG28j",
        "4z2CWyZcHqH2",
        "M21b_PAywDLg",
        "d4kdgCzG0i-a",
        "N_NGoX4sTfsn",
        "zSwaRFfoJibG"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5"
    },
    "vscode": {
      "interpreter": {
        "hash": "ffde0a50f840762247d315ede7f5ba1a4f2c4918fd6179a6eeec16d20d9d21d6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
